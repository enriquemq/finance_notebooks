{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previsão IPCA mês seguinte: Vetores Autoregressivos vs. Machine Learning com conjunto de informação comum\n",
    "\n",
    "Neste notebook é feito um exercício de comparação da acurácia das previsões de um modelo de vetores autoregressivos com as previsões de diversos modelos de Machine-Learning **usando o mesmo conjunto de informação**. O objetivo do exercício é verificar se, mesmo em um contexto de poucas variáveis explicativas, os modelos ML tem performance melhor que modelos VAR. Além disso, comparamos as previsões usando *expanding window* vs. *rolling window*.  \n",
    "\n",
    "Todos os dados utilizados foram extraídos do Banco Central através do pacote `sgs` (https://github.com/rafpyprog/pySGS)\n",
    "\n",
    "O modelo VAR usado é basedo no VAR I (https://www.bcb.gov.br/htms/relinf/port/2012/09/ri201209P.pdf, página 107) do Banco Central e tem as seguintes características:  \n",
    "- Sem ajuste sazonal  \n",
    "- Lag 2  \n",
    "- Deflator do juros: IGP-M (série 189)  \n",
    "- Variáveis endógenas: Preços livres (série 11428), Preços administrados (série 4449), Taxa de câmbio (série 3696) e Taxa de juros reais = Selic (série 4189) - deflator  \n",
    "\n",
    "**O modelos de machine learning utilizados são**:\n",
    "- Boosting\n",
    "- Random Forest\n",
    "- SVM\n",
    "- Regressão Linear\n",
    "\n",
    "Como o VAR I usa duas defasagens, precisamos dos dados do mês atual e do mês anterior para prever o inflação do mês seguinte. Por esse motivo, construo uma base para os modelos de ML onde, para cada data, os features são o valor contemporâneo das variáveis endógenas utilizadas no VAR I e o valor do mês anterior destas mesmas séries. Obviamente, o target dos modelos será o IPCA no mês seguinte. Ainda, como o número de dados disponíveis não é muito grande, foi decidido não realizar *tunning* dos hiperparâmetros dos modelos para evitar ao máximo problemas de overfitting.  \n",
    "Por fim, como o ano de 2020 foi marcado pelo grande choque econômico gerado pela pandemia do COVID-19, é feita a comparação para resultados pré início da pandemia e pós início da pandemia.  \n",
    "\n",
    "Abaixo apresento e analiso os resultados obtidos e, em seguida, exponho o código utilizado para realizar a análise.  \n",
    "*Portanto o notebook não pode ser replicado de forma linear (observar numeração ao lado das células de códigos)!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados e análise:\n",
    "Tendo rodado o código para o período pré covid e salvando o resultado como `metricas_pré_pandemia` e, posteriormente, rodado para o período pós início da pandemia e salvando o resultado como `metricas_pandemia`, montamos a base de dados do resultado consolidada da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE_pré</th>\n",
       "      <th>Mean Error_pré</th>\n",
       "      <th>MSE_pós</th>\n",
       "      <th>Mean Error_pós</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modelo</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>var1_forecasts_exp</th>\n",
       "      <td>0.073368</td>\n",
       "      <td>0.058797</td>\n",
       "      <td>0.080728</td>\n",
       "      <td>0.063531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var1_forecasts_rol</th>\n",
       "      <td>0.069442</td>\n",
       "      <td>0.024223</td>\n",
       "      <td>0.078721</td>\n",
       "      <td>0.032849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boost_exp</th>\n",
       "      <td>0.093009</td>\n",
       "      <td>0.061905</td>\n",
       "      <td>0.101697</td>\n",
       "      <td>0.067517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_exp</th>\n",
       "      <td>0.087961</td>\n",
       "      <td>0.057357</td>\n",
       "      <td>0.088836</td>\n",
       "      <td>0.063182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_exp</th>\n",
       "      <td>0.074371</td>\n",
       "      <td>0.051713</td>\n",
       "      <td>0.084430</td>\n",
       "      <td>0.060095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linreg_exp</th>\n",
       "      <td>0.073410</td>\n",
       "      <td>0.062150</td>\n",
       "      <td>0.080700</td>\n",
       "      <td>0.066620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boost_rol</th>\n",
       "      <td>0.064479</td>\n",
       "      <td>0.013049</td>\n",
       "      <td>0.079808</td>\n",
       "      <td>0.027711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_rol</th>\n",
       "      <td>0.061378</td>\n",
       "      <td>0.015668</td>\n",
       "      <td>0.072337</td>\n",
       "      <td>0.030072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_rol</th>\n",
       "      <td>0.078578</td>\n",
       "      <td>0.033560</td>\n",
       "      <td>0.083862</td>\n",
       "      <td>0.039358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linreg_rol</th>\n",
       "      <td>0.067761</td>\n",
       "      <td>0.021187</td>\n",
       "      <td>0.073897</td>\n",
       "      <td>0.027370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     MSE_pré  Mean Error_pré   MSE_pós  Mean Error_pós\n",
       "modelo                                                                \n",
       "var1_forecasts_exp  0.073368        0.058797  0.080728        0.063531\n",
       "var1_forecasts_rol  0.069442        0.024223  0.078721        0.032849\n",
       "boost_exp           0.093009        0.061905  0.101697        0.067517\n",
       "rf_exp              0.087961        0.057357  0.088836        0.063182\n",
       "svm_exp             0.074371        0.051713  0.084430        0.060095\n",
       "linreg_exp          0.073410        0.062150  0.080700        0.066620\n",
       "boost_rol           0.064479        0.013049  0.079808        0.027711\n",
       "rf_rol              0.061378        0.015668  0.072337        0.030072\n",
       "svm_rol             0.078578        0.033560  0.083862        0.039358\n",
       "linreg_rol          0.067761        0.021187  0.073897        0.027370"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metricas_pandemia = metricas_pandemia.add_suffix('_pós')\n",
    "metricas_pandemia.index.name = 'modelo'\n",
    "metricas_pre_pandemia = metricas_pre_pandemia.add_suffix('_pré')\n",
    "metricas_pre_pandemia.index.name = 'modelo'\n",
    "metricas_consolidadas = metricas_pre_pandemia.merge(metricas_pandemia, on='modelo')\n",
    "metricas_consolidadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise dos resultados:\n",
    "\n",
    "Começando com observações gerais, primeiro nota-se que (exceto para o SVM) todos os modelos apresentaram erro quadrático médio menor nas previsões com *rolling window* do que nas previsões com *expanding window*. Isso pode ser um indício de diferentes regimes para o processo de inflação (para mais sobre modelo de diferentes regimes para inflação ver Amisano e Fagan, 2013). Em segundo lugar, observa-se que todos os modelos apresentam erro médio positivo, mostrando que todos tem tendência em superestimar o IPCA. Uma possível explicação para este fenômeno pode ser dado pelo fato de que o comportamento da inflação a partir da metade da amostra analisada é de queda acentuada. Por fim os modelos tiveram performance pior na amostra que inclui o período da pandemia. Tal resultado era esperado tanto pelo choque externo da pandemia quanto pelo aumento da volatilidade da inflação.  \n",
    "\n",
    "Agora comparando o erro quadrático médio dos modelos, temos que os 3 melhores resultados para o período pré pandemia foram (em ordem do melhor para o pior): Random Forest com rolling window, Boosting com rolling window e Regressão Linear com rolling window. Para o período pós início da pandemia os 3 melhores foram: Random Forest com rolling window, Regressão Linear com rolling window, VAR com rolling window. Destaca-se, então, a boa performance do modelo de Random Forest com rolling window, corroborando com o resultado apresentado em Medeiros et al, 2019. Além disso, **com o mesmo conjunto de informação**, o modelo VAR consegue se manter no mesmo patamar de performance que modelos ML.  \n",
    "\n",
    "Por fim, é importante ressaltar que **os modelos de ML não foram utilizados em todo seu potencial**. Primeiro, não foi feito nenhum esforço de *tunning* dos modelos de ML, sendo todos utilizados com seus hiperparâmetros padrões do pacote `scikit-learn`. Segundo, e ainda mais relevante, ao usar o mesmo conjunto de informação que o modelo VAR I abrimos mão da capacidade dos modelos de ML em assimilar um grande número de variáveis. Neste contexto, o resultado de que o modelo RF performa melhor que o modelo VAR I mesmo com poucas variáveis explicativas é bastante forte e demonstra que o uso destes modelos pode não ser necessariamente restrito aos casos de alta dimensão de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código\n",
    "Os resultados foram obtidos rodando o seguinte código:  \n",
    "**Atenção**: o código foi rodado uma vez para o período pré covid (previsões até jan/2020) e outra para o período pós choque do covid (previsões indo até o fim da amostra). Ou seja, **para replicar o resultado é necessário rodar o código duas vezes**, usando o período desejado e salvando o resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sgs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from datetime import datetime, date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "### Parâmetros ###\n",
    "##################\n",
    "\n",
    "#Janela dos dados a serem baixados (não é o janela do backtest!!!)\n",
    "start = '01/01/2001' #primeira data dos dados\n",
    "end = '05/11/2020'   #ultima data dos dados\n",
    "\n",
    "# Dicionários das séries a serem baixadas\n",
    "var1_codigos = {'precos_livres': 11428,\n",
    "        'precos_adm': 4449,\n",
    "        'cambio': 3696,\n",
    "        'selic': 4189,\n",
    "        'deflator':189}\n",
    "\n",
    "# Parametrôs para o loop:\n",
    "data_ = date(2006,1,1) # primeiro forecast é para data_ + 1 mês\n",
    "end_date = date(2019, 12, 1) #ultimo forecast é para end_date + 1 mês\n",
    "\n",
    "delta = relativedelta(months=1) # pular de mês em mês\n",
    "delta_5anos = relativedelta(months=60) # rolling window de 5 anos\n",
    "\n",
    "# Modelos Ml (botar os modelos que quiser rodar aqui):\n",
    "boost = GradientBoostingRegressor()\n",
    "rf = RandomForestRegressor()\n",
    "svm = SVR()\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# Dicionário para usar no loop (adicionar os modelos selecionados nesse dicionário)\n",
    "models = {'boost': boost, 'rf': rf, 'svm': svm, 'linreg': linreg}\n",
    "\n",
    "# Séries auxilares\n",
    "var1_forecasts_exp = []\n",
    "var1_forecasts_rol = []\n",
    "ipca_real = []\n",
    "index_data = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegando dados do SGS do Bacen\n",
    "ipca = sgs.time_serie(433, start, end) # Para comparar forecasts com o realizado\n",
    "\n",
    "var1_series = {}\n",
    "\n",
    "for k, v in var1_codigos.items():\n",
    "    var1_series[k] = sgs.time_serie(v, start = start, end = end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montar base para o os modelos de ML:\n",
    "ml_df = pd.DataFrame.from_dict(var1_series)\n",
    "ml_df['juros_real'] = ml_df['selic'] - ml_df['deflator']\n",
    "ml_df = ml_df.dropna()\n",
    "ml_df = ml_df[['precos_livres', 'precos_adm', 'cambio', 'juros_real']]\n",
    "\n",
    "# Usando lag 1 para ter a mesmo conjunto de informação que o VAR\n",
    "for col in ml_df:\n",
    "    name = col + '_lag1'\n",
    "    ml_df[name] = ml_df[col].shift()\n",
    "ml_df['target'] = ipca.shift(-1)\n",
    "ml_df = ml_df.dropna()\n",
    "\n",
    "# Teste raiz unitária:\n",
    "for col in ml_df:\n",
    "    adf = adfuller(ml_df[col])\n",
    "    if adf[1] > 0.10:\n",
    "        new_name = col + '_dif'\n",
    "        ml_df[col] = ml_df[col].diff()\n",
    "        ml_df = ml_df.rename({col: new_name}, axis = 1)\n",
    "ml_df = ml_df.dropna()\n",
    "\n",
    "# Dividindo base em features e target\n",
    "X = ml_df.iloc[:,:-1]\n",
    "Y = ml_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função para usar no loop ML:\n",
    "def get_forecast(model, X_train, Y_train, X_test):\n",
    "    \n",
    "    model.fit(X_train, Y_train)\n",
    "    return model.predict(X_test)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando os loops do VAR dos loops do ML para facilitar a leitura do código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "### Rolling Window Loop VAR ###\n",
    "###############################\n",
    "data = data_\n",
    "while data <= end_date:\n",
    "    index_data.append(data)\n",
    "    \n",
    "    precos_livres = var1_series['precos_livres'][start:data]\n",
    "    precos_adm = var1_series['precos_adm'][start:data]\n",
    "    \n",
    "    # Montando o DataFrame\n",
    "    var1_df = pd.DataFrame.from_dict(var1_series)\n",
    "    var1_df['juros_real'] = var1_df['selic'] - var1_df['deflator']\n",
    "    var1_df = var1_df.dropna()\n",
    "    var1_df = var1_df[['precos_livres', 'precos_adm', 'cambio', 'juros_real']]\n",
    "    var1_df = var1_df[start:data]\n",
    "\n",
    "    # Teste raiz unitária e botando variáveis com raiz unitária em diferenças\n",
    "    for col in var1_df:\n",
    "        adf = adfuller(var1_df[col])\n",
    "        if adf[1] > 0.10:\n",
    "            new_name = col + '_dif' # renomeando caso a variável seja transformada para diferenças    \n",
    "            var1_df[col] = var1_df[col].diff()\n",
    "            var1_df = var1_df.rename({col: new_name}, axis = 1)\n",
    "    var1_df = var1_df.dropna()\n",
    "    \n",
    "    # Rodando o modelo\n",
    "    var1_model = VAR(var1_df)\n",
    "    var1_resultado = var1_model.fit(2) #usando o Lag apontado pelo BACEN\n",
    "    \n",
    "    ## Calculando a previsão do IPCA para o mês seguinte\n",
    "    #1) pegando o peso dos preços adm:\n",
    "    p_serie = (ipca[:data] - precos_livres)/(precos_adm - precos_livres)\n",
    "    p = p_serie[-1]\n",
    "\n",
    "    # Evitar problemas nos dados. Tem data em que p = 0 ou p = NaN! Nestes casos usar dado da data anterior\n",
    "    if p < 0.05 or str(p) == 'nan':\n",
    "        p = p_serie[-2]\n",
    "\n",
    "\n",
    "    #2) Calculando o forecast (se tiver em diferenças somar o forecast ao valor anterior)\n",
    "    forecast = var1_resultado.forecast(var1_df.values[-2:],1)[0]\n",
    "\n",
    "    #Preços Livres\n",
    "    if 'dif' in var1_df.iloc[:,0].name:\n",
    "        var1_forecast_precos_livres = forecast[0] + precos_livres[-1]\n",
    "    else:\n",
    "        var1_forecast_precos_livres = forecast[0]\n",
    "    \n",
    "    #Preços administrados\n",
    "    if 'dif' in var1_df.iloc[:,1].name:\n",
    "        var1_forecast_precos_adm = forecast[1] + precos_adm[-1]\n",
    "    else:\n",
    "        var1_forecast_precos_adm = forecast[1]\n",
    "    \n",
    "    #IPCA\n",
    "    var1_forecast_ipca = (1-p)*var1_forecast_precos_livres + p*var1_forecast_precos_adm\n",
    "    var1_forecasts_exp.append(var1_forecast_ipca)\n",
    "    \n",
    "    \n",
    "    # Próxima Data!\n",
    "    data += delta\n",
    "    ipca_real.append(ipca[data])\n",
    "    \n",
    "    \n",
    "#################################\n",
    "### Expanding Window Loop VAR ###\n",
    "#################################\n",
    "data = data_\n",
    "while data <= end_date:\n",
    "    start = data - delta_5anos\n",
    "    precos_livres = var1_series['precos_livres'][start:data]\n",
    "    precos_adm = var1_series['precos_adm'][start:data]\n",
    "    \n",
    "    # Montando o DataFrame\n",
    "    var1_df = pd.DataFrame.from_dict(var1_series)\n",
    "    var1_df['juros_real'] = var1_df['selic'] - var1_df['deflator']\n",
    "    var1_df = var1_df.dropna()\n",
    "    var1_df = var1_df[['precos_livres', 'precos_adm', 'cambio', 'juros_real']]\n",
    "    var1_df = var1_df[start:data]\n",
    "\n",
    "    # Teste raiz unitária e botando variáveis com raiz unitária em diferenças\n",
    "    for col in var1_df:\n",
    "        adf = adfuller(var1_df[col])\n",
    "        if adf[1] > 0.10:\n",
    "            new_name = col + '_dif'\n",
    "            var1_df[col] = var1_df[col].diff()\n",
    "            var1_df = var1_df.rename({col: new_name}, axis = 1)\n",
    "    var1_df = var1_df.dropna()\n",
    "    \n",
    "    # Rodando o modelo\n",
    "    var1_model = VAR(var1_df)\n",
    "    var1_resultado = var1_model.fit(2) #usando o Lag apontado pelo BACEN\n",
    "    \n",
    "    ## Calculando a previsão do IPCA para o mês seguinte\n",
    "    #1) pegando o peso dos preços adm:\n",
    "    p_serie = (ipca[:data] - precos_livres)/(precos_adm - precos_livres)\n",
    "    p = p_serie[-1]\n",
    "\n",
    "    # Evitar problemas nos dados. Tem data em que p = 0 ou p = NaN! Nestes casos usar dado da data anterior\n",
    "    if p < 0.05 or str(p) == 'nan':\n",
    "        p = p_serie[-2]\n",
    "\n",
    "\n",
    "    #2) Calculando o forecast (se tiver em diferenças somar o forecast ao valor anterior)\n",
    "    forecast = var1_resultado.forecast(var1_df.values[-2:],1)[0]\n",
    "\n",
    "    #Preços Livres:\n",
    "    if 'dif' in var1_df.iloc[:,0].name:\n",
    "        var1_forecast_precos_livres = forecast[0] + precos_livres[-1]\n",
    "    else:\n",
    "        var1_forecast_precos_livres = forecast[0]\n",
    "    \n",
    "    #Preços administrados:\n",
    "    if 'dif' in var1_df.iloc[:,1].name:\n",
    "        var1_forecast_precos_adm = forecast[1] + precos_adm[-1]\n",
    "    else:\n",
    "        var1_forecast_precos_adm = forecast[1]\n",
    "    \n",
    "    #IPCA\n",
    "    var1_forecast_ipca = (1-p)*var1_forecast_precos_livres + p*var1_forecast_precos_adm\n",
    "    var1_forecasts_rol.append(var1_forecast_ipca)\n",
    "    \n",
    "    \n",
    "    # Próxima Data!\n",
    "    data += delta\n",
    "    \n",
    "var1_for_resultados = pd.DataFrame([index_data, ipca_real, var1_forecasts_exp, var1_forecasts_rol]).transpose()\n",
    "var1_for_resultados.columns = ['Data', 'IPCA', 'var1_forecasts_exp', 'var1_forecasts_rol']\n",
    "var1_for_resultados = var1_for_resultados.set_index('Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = '01/01/2001' #Reiniciar o start pq rolling window loop do var altera\n",
    "index_data = [] #Para poder rodar o Loop independete do loop do var\n",
    "#######################################\n",
    "### Expanding Window Loop ML Models ###\n",
    "#######################################\n",
    "exp = [] # lista para salvar os forecasts \n",
    "data = data_ \n",
    "while data <= end_date:\n",
    "    index_data.append(data)\n",
    "    \n",
    "    # Selecionando a subamostra\n",
    "    X_ = X[start:data]\n",
    "    Y_ = Y[start:data]\n",
    "    X_train = X_[:-1]\n",
    "    Y_train = Y_[:-1]\n",
    "    X_test = X_[-1:]\n",
    "    \n",
    "    # Rodando os modelos\n",
    "    lista_aux = []\n",
    "    for model in models.values():\n",
    "            lista_aux.append(get_forecast(model, X_train, Y_train, X_test))\n",
    "    exp.append(lista_aux)    \n",
    "    \n",
    "    data = data + delta\n",
    "\n",
    "# Montando df\n",
    "exp = pd.DataFrame(exp, index = index_data, columns = models.keys())\n",
    "exp = exp.add_suffix('_exp')\n",
    "exp.index.name = 'Data'\n",
    "\n",
    "#####################################\n",
    "### Rolling Window Loop ML Models ###\n",
    "#####################################\n",
    "rol = []\n",
    "data = data_\n",
    "while data <= end_date:\n",
    "    start = data - delta_5anos\n",
    "    \n",
    "    # Selecionando a subamostra\n",
    "    X_ = X[start:data]\n",
    "    Y_ = Y[start:data]\n",
    "    X_train = X_[:-1]\n",
    "    Y_train = Y_[:-1]\n",
    "    X_test = X_[-1:]\n",
    "\n",
    "    # Rodando os modelos\n",
    "    lista_aux = []\n",
    "    for model in models.values():\n",
    "            lista_aux.append(get_forecast(model, X_train, Y_train, X_test))\n",
    "    rol.append(lista_aux)    \n",
    "    data = data + delta\n",
    "\n",
    "# Montando df\n",
    "rol = pd.DataFrame(rol, index = index_data, columns = models.keys())\n",
    "rol = rol.add_suffix('_rol')\n",
    "rol.index.name = 'Data'\n",
    "\n",
    "# Juntando os dois df\n",
    "forecasts_ml = exp.merge(rol, on = 'Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# juntando a base d forecasts do var com a base de forecasts dos modelos ML\n",
    "resultado = var1_for_resultados.merge(forecasts_ml, on = 'Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando MSE e erro médio e juntando um um df\n",
    "metricas = pd.DataFrame(index = resultado.columns[1:])\n",
    "mse_list = []\n",
    "mean_error_list = []\n",
    "for col in resultado:\n",
    "    mse = np.sum((resultado['IPCA'] - resultado[col])**2)/resultado.shape[0]\n",
    "    mean_error = np.mean(resultado[col] - resultado['IPCA'])\n",
    "    if mse > 0: # para pular a coluna do IPCA\n",
    "        mse_list.append(mse)\n",
    "        mean_error_list.append(mean_error)\n",
    "metricas['MSE'] = mse_list\n",
    "metricas['Mean Error'] = mean_error_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referências:\n",
    "**Amisano, G. and G. Fagan, 2013**. Money growth and inflation: a regime switching approach,” Journal of International Money and Finance, 33, 118-145\n",
    "\n",
    "**Medeiros, M. C., Vasconcelos, G. F., Veiga, Á., and Zilberman, E., 2019**. Forecasting Inflation\n",
    "in a Data-Rich Environment: The Benefits of Machine Learning Methods. Journal of Business\n",
    "and Economic Statistics, 0, 1–45\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
